{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import utils.feature_extractors as utils\n",
    "import optuna\n",
    "import joblib\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from utils.utils import evaluate_classification\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_map = {\n",
    "    \"train_postive_location\":\"dataset/TR_pos_SPIDER.txt\",\n",
    "    \"train_negative_location\":\"dataset/TR_neg_SPIDER.txt\",\n",
    "    \"test_positive_location\":\"dataset/TS_pos_SPIDER.txt\",\n",
    "    \"test_negative_location\":\"dataset/TS_neg_SPIDER.txt\",\n",
    "    \"model_save_location\":\"./optimized_models\",\n",
    "    \"feat_combo_model_save_location\":\"./feature_combo_models\",\n",
    "    \"final_model_save_location\":\"./final_model\",\n",
    "    \"random_seed\":9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProteinFeatureGenerator:\n",
    "    SELECTED_FEATURES = [\"AAC\", \"DPC\", \"RScharge\", \"RSDHP\", \"RSpolar\"]\n",
    "    \n",
    "    def __init__(self, positive_data_file: str, negative_data_file: str, feature_type: str = None) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        # Check feature param\n",
    "        assert feature_type in ProteinFeatureGenerator.SELECTED_FEATURES or feature_type is None\n",
    "        self.feature_type = feature_type\n",
    "\n",
    "        # Data manipulation\n",
    "        self.positive_data_file = positive_data_file\n",
    "        self.negative_data_file = negative_data_file\n",
    "\n",
    "        self.positive_data = utils.read_fasta(self.positive_data_file)\n",
    "        self.negative_data = utils.read_fasta(self.negative_data_file)\n",
    "        self.data = self.positive_data + self.negative_data\n",
    "\n",
    "        self.targets = np.array([True]*len(self.positive_data) + [False]*len(self.negative_data))\n",
    "        \n",
    "\n",
    "        self.raw_sequences = [x[1] for x in self.data]\n",
    "        \n",
    "        \n",
    "        print(\"Extracting AAC Feature ...\")\n",
    "        self.AAC_feature = utils.AAC(self.data)[0]\n",
    "\n",
    "        print(\"Extracting DPC Feature ...\")\n",
    "        self.DPC_feature = utils.DPC(self.data, 0)[0]\n",
    "\n",
    "        print(\"Extracting RScharge Feature ...\")\n",
    "        self.RScharge_feature = utils.reducedCHARGE(self.data)\n",
    "        \n",
    "        print(\"Extracting RSDHP Feature ...\")\n",
    "        self.RSDHP_feature = utils.reducedDHP(self.data)\n",
    "        \n",
    "        print(\"Extracting RSpolar Feature ...\")\n",
    "        self.RSpolar_feature = utils.reducedPOLAR(self.data)\n",
    "\n",
    "    def get_feat_combo(self,selected:list = None):\n",
    "        \n",
    "        features =[self.AAC_feature,self.DPC_feature,self.RScharge_feature,self.RSDHP_feature,self.RSpolar_feature]\n",
    "        \n",
    "        if selected:\n",
    "            select_index = sorted([ProteinFeatureGenerator.SELECTED_FEATURES.index(x) for x in selected])\n",
    "            features = [features[x] for x in select_index]\n",
    "            \n",
    "        return np.concatenate(features,axis=-1)\n",
    "        \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting AAC Feature ...\n",
      "Extracting DPC Feature ...\n",
      "Extracting RScharge Feature ...\n",
      "Extracting RSDHP Feature ...\n",
      "Extracting RSpolar Feature ...\n"
     ]
    }
   ],
   "source": [
    "test_data = ProteinFeatureGenerator(positive_data_file=config_map[\"test_positive_location\"],negative_data_file=config_map[\"test_negative_location\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = {\n",
    "    \"AAC-DPC-RScharge-RSDHP-RSpolar\":test_data.get_feat_combo([\"AAC\",\"DPC\",\"RScharge\",\"RSDHP\",\"RSpolar\"]),\n",
    "    \"AAC\":test_data.AAC_feature,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_model_dir = \"optimized_models\\AAC\\SVC\"\n",
    "combine_model_dir = \"final_model\\AAC-DPC-RScharge-RSDHP-RSpolar\\SVC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_type=\"AAC\"\n",
    "X,y = X_test[feature_type],test_data.targets\n",
    "pipeline =joblib.load(os.path.join(single_model_dir,\"pipeline.sav\")) \n",
    "clf = joblib.load(os.path.join(single_model_dir,\"model.sav\"))\n",
    "X = pipeline.transform(X)\n",
    "y_pred_single_model = clf.predict(X)\n",
    "\n",
    "feature_combo=\"AAC-DPC-RScharge-RSDHP-RSpolar\"\n",
    "X,y = X_test[feature_combo],test_data.targets\n",
    "pipeline =joblib.load(os.path.join(combine_model_dir,\"pipeline.sav\"))\n",
    "clf = joblib.load(os.path.join(combine_model_dir,\"model.sav\"))\n",
    "X = pipeline.transform(X)\n",
    "y_pred_combined_model = clf.predict(X)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## McNemar's Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "McNemar's test compares the performance of two classifiers on a binary classification task by counting how often they agree or disagree. A contingency table is constructed to evaluate the difference between the two classifiers' error rates. If the p-value is below 0.05, it is concluded that the two classifiers have significantly different error rates/accuracies."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Null hypothesis of McNemar's test is that the two models have the same accuracy, while the alternative hypothesis is that they have different accuracies. The test computes a chi-squared statistic based on the number of discordant pairs (i.e., instances that are classified correctly by one model but incorrectly by the other) and uses a chi-squared distribution to calculate a p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "combined_model_correct  False  True \n",
      "single_model_correct                \n",
      "False                      46      7\n",
      "True                       16    392\n",
      "\n",
      "\n",
      "McNemar's test statistic: 3.5217391304347827\n",
      "p-value: 0.060568860202657615\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary to store the data\n",
    "data_dict = {\n",
    "    \"target\": y,\n",
    "    \"single_model_predictions\": y_pred_single_model,\n",
    "    \"combined_model_predictions\": y_pred_combined_model\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame from the dictionary\n",
    "significance_test_df = pd.DataFrame(data_dict)\n",
    "\n",
    "# Create new columns to check if the single_model and combined_model predictions are correct\n",
    "significance_test_df[\"single_model_correct\"] = significance_test_df[\"target\"] == significance_test_df[\"single_model_predictions\"]\n",
    "significance_test_df[\"combined_model_correct\"] = significance_test_df[\"target\"] == significance_test_df[\"combined_model_predictions\"]\n",
    "\n",
    "# Create the contingency table\n",
    "contingency_table = pd.crosstab(significance_test_df[\"single_model_correct\"], significance_test_df[\"combined_model_correct\"])\n",
    "print(contingency_table)\n",
    "# Compute the test statistic and p-value\n",
    "a = contingency_table.iloc[0,1]\n",
    "b = contingency_table.iloc[1,0]\n",
    "\n",
    "mcnemar_statistic = ((b - a) ** 2) / (b + a)\n",
    "p_value = 1 - stats.chi2.cdf(mcnemar_statistic, df=1)\n",
    "\n",
    "# Print the contingency table and test results\n",
    "print('\\n')\n",
    "print(\"McNemar's test statistic:\", mcnemar_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, the p-value obtained from the McNemar's test is 0.0605, which is greater than 0.05. Therefore, we fail to reject the null hypothesis at the 5% significance level. This means that we do not have sufficient evidence to conclude that the combined model is significantly different from the single model in terms of predictive accuracy at the 5% significance level."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
